{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "smpEEHlypz0p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toy Data"
      ],
      "metadata": {
        "id": "PAgmRCdTvyg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([[ 8.7541382e+01,  7.4368027e+01,  6.8198807e+01,  5.5106983e+01,\n",
        "         3.8173203e+01,  2.3811323e+01,  1.8535612e+01,  1.8095873e+01],\n",
        "       [-5.1816605e-02,  4.1964740e-01,  4.4769207e-01, -6.5377988e-02,\n",
        "         6.1878175e-01,  6.2997532e-01, -8.1161506e-02, -7.9315454e-02],\n",
        "       [ 2.4468634e+00,  2.2728169e+00,  2.2340939e+00,  2.6091626e+00,\n",
        "         1.8117365e+00,  1.7758595e+00,  2.3642292e+00,  2.5458102e+00],\n",
        "       [ 8.7658936e+01,  8.1014442e+01,  7.5148209e+01,  5.5224800e+01,\n",
        "         4.5717682e+01,  2.8694658e+01,  1.8596695e+01,  1.8153358e+01]])\n",
        "\n",
        "x_batch = torch.Tensor([[[ 8.7541382e+01,  7.4368027e+01,  6.8198807e+01,  5.5106983e+01,\n",
        "          3.8173203e+01,  2.3811323e+01,  1.8535612e+01,  1.8095873e+01],\n",
        "        [-5.1816605e-02,  4.1964740e-01,  4.4769207e-01, -6.5377988e-02,\n",
        "          6.1878175e-01,  6.2997532e-01, -8.1161506e-02, -7.9315454e-02],\n",
        "        [ 2.4468634e+00,  2.2728169e+00,  2.2340939e+00,  2.6091626e+00,\n",
        "          1.8117365e+00,  1.7758595e+00,  2.3642292e+00,  2.5458102e+00],\n",
        "        [ 8.7658936e+01,  8.1014442e+01,  7.5148209e+01,  5.5224800e+01,\n",
        "          4.5717682e+01,  2.8694658e+01,  1.8596695e+01,  1.8153358e+01]],\n",
        "\n",
        "       [[ 8.2484528e+01,  5.2682617e+01,  5.1243843e+01,  3.6217686e+01,\n",
        "          2.8948278e+01,  2.6579512e+01,  2.1946012e+01,  2.1011120e+01],\n",
        "        [-4.3566185e-01, -8.7309110e-01, -4.4896263e-01, -6.0569459e-01,\n",
        "         -4.8134822e-01, -7.0045888e-01, -6.0671657e-01, -5.7662535e-01],\n",
        "        [-1.9739739e+00, -2.4504409e+00, -1.9982951e+00, -1.4225215e+00,\n",
        "         -1.9399333e+00, -2.3558097e+00, -1.4185165e+00, -1.4236869e+00],\n",
        "        [ 9.0437065e+01,  7.4070679e+01,  5.6495895e+01,  4.3069641e+01,\n",
        "          3.2367134e+01,  3.3371326e+01,  2.6115334e+01,  2.4602446e+01]],\n",
        "\n",
        "       [[ 8.6492935e+01,  7.0192978e+01,  5.8423912e+01,  5.6638733e+01,\n",
        "          4.9270725e+01,  4.1237038e+01,  3.6133625e+01,  3.5519596e+01],\n",
        "        [ 1.4010678e-01,  2.7912292e-01,  1.4376265e-01,  3.4672296e-01,\n",
        "          3.4966472e-01,  1.0524009e-01,  1.2958543e-01,  3.3264065e-01],\n",
        "        [ 1.9334941e+00,  1.6967584e+00,  1.9219695e+00,  1.6735281e+00,\n",
        "          1.6587850e+00,  1.8386338e+00,  1.9120301e+00,  1.6680365e+00],\n",
        "        [ 8.7343246e+01,  7.2945129e+01,  5.9030762e+01,  6.0084766e+01,\n",
        "          5.2313778e+01,  4.1465607e+01,  3.6440781e+01,  3.7506149e+01]]])"
      ],
      "metadata": {
        "id": "2jsmzKcFvx4L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.unsqueeze(0) # batch dimension\n",
        "x.shape, x_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po7Fb1v37EJT",
        "outputId": "2571d4f4-e9db-4e2b-ee7f-13a7e406e526"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 4, 8]), torch.Size([3, 4, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantum Function"
      ],
      "metadata": {
        "id": "-ybT64WoWQ71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.ComplexWarning = Warning\n",
        "\n",
        "!pip install tensorcircuit\n",
        "from typing import Callable\n",
        "\n",
        "import tensorcircuit as tc\n",
        "import jax.numpy as jnp\n",
        "import flax.linen\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import tensorcircuit as tc\n",
        "\n",
        "K = tc.set_backend(\"jax\")\n",
        "\n",
        "\n",
        "def angle_embedding(c: tc.Circuit, inputs):\n",
        "    num_qubits = inputs.shape[-1]\n",
        "\n",
        "    for j in range(num_qubits):\n",
        "        c.rx(j, theta=inputs[j])\n",
        "\n",
        "\n",
        "def basic_vqc(c: tc.Circuit, inputs, weights):\n",
        "    num_qubits = inputs.shape[-1]\n",
        "    num_qlayers = weights.shape[-2]\n",
        "\n",
        "    for i in range(num_qlayers):\n",
        "        for j in range(num_qubits):\n",
        "            c.rx(j, theta=weights[i, j])\n",
        "        if num_qubits == 2:\n",
        "            c.cnot(0, 1)\n",
        "        elif num_qubits > 2:\n",
        "            for j in range(num_qubits):\n",
        "                c.cnot(j, (j + 1) % num_qubits)\n",
        "\n",
        "\n",
        "def get_quantum_layer_circuit(inputs, weights,\n",
        "                              embedding: Callable = angle_embedding, vqc: Callable = basic_vqc):\n",
        "    \"\"\"\n",
        "    Equivalent to the following PennyLane circuit:\n",
        "        def circuit(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=range(num_qubits))\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=range(num_qubits))\n",
        "    \"\"\"\n",
        "\n",
        "    num_qubits = inputs.shape[-1]\n",
        "\n",
        "    c = tc.Circuit(num_qubits)\n",
        "    embedding(c, inputs)\n",
        "    vqc(c, inputs, weights)\n",
        "\n",
        "    return c\n",
        "\n",
        "\n",
        "def get_circuit(embedding: Callable = angle_embedding, vqc: Callable = basic_vqc,\n",
        "                torch_interface: bool = False):\n",
        "    def qpred(inputs, weights):\n",
        "        c = get_quantum_layer_circuit(inputs, weights, embedding, vqc)\n",
        "        return K.real(jnp.array([c.expectation_ps(z=[i]) for i in range(weights.shape[1])]))\n",
        "\n",
        "    qpred_batch = K.vmap(qpred, vectorized_argnums=0)\n",
        "    if torch_interface:\n",
        "        qpred_batch = tc.interfaces.torch_interface(qpred_batch, jit=True)\n",
        "\n",
        "    return qpred_batch\n",
        "\n",
        "\n",
        "class QuantumLayer(flax.linen.Module):\n",
        "    circuit: Callable\n",
        "    num_qubits: int\n",
        "    w_shape: tuple = (1,)\n",
        "\n",
        "    @flax.linen.compact\n",
        "    def __call__(self, x):\n",
        "        shape = x.shape\n",
        "        x = jnp.reshape(x, (-1, shape[-1]))\n",
        "        w = self.param('w', flax.linen.initializers.xavier_normal(), self.w_shape + (self.num_qubits,))\n",
        "        x = self.circuit(x, w)\n",
        "        x = jnp.concatenate(x, axis=-1)\n",
        "        x = jnp.reshape(x, tuple(shape))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "NUM_QUBITS     = 8\n",
        "NUM_Q_LAYERS   = 1\n",
        "torch_layer_fn = get_circuit(torch_interface=True)\n",
        "\n",
        "\n",
        "class TCTorchLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A thin PyTorch wrapper around the TensorCircuit/TC quantum layer.\n",
        "    Stores the circuit's trainable parameters as an nn.Parameter so\n",
        "    they appear in .parameters() and get updated by any torch optimizer.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_qubits=NUM_QUBITS, num_qlayers=NUM_Q_LAYERS):\n",
        "        super().__init__()\n",
        "        init_w = 0.01 * torch.randn(num_qlayers, num_qubits)\n",
        "        self.w = nn.Parameter(init_w)\n",
        "        self.num_qubits = num_qubits\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, num_qubits) – already pre-scaled into rotation angles.\n",
        "        Returns expectation values ⟨Z_i⟩ for every qubit i, shape identical\n",
        "        to the input (batch, num_qubits).\n",
        "        \"\"\"\n",
        "        return torch_layer_fn(x, self.w)\n",
        "\n",
        "\n",
        "class QuantumLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear -> angle map -> TCTorchLayer -> Linear\n",
        "    Works on tensors shaped (..., din) and returns (..., dout).\n",
        "    \"\"\"\n",
        "    def __init__(self, din, dout, num_qubits):\n",
        "        super().__init__()\n",
        "        self.din  = din\n",
        "        self.dout = dout\n",
        "        self.nq   = num_qubits\n",
        "\n",
        "        self.to_q   = nn.Linear(din,  self.nq, bias=False)\n",
        "        self.from_q = nn.Linear(self.nq, dout, bias=False)\n",
        "        self.q = TCTorchLayer(self.nq)\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_angles(x):\n",
        "        return torch.tanh(x) * math.pi\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (..., din)\n",
        "        *prefix, _ = x.shape\n",
        "        x = x.reshape(-1, self.din)\n",
        "\n",
        "        x = self.to_q(x)\n",
        "        x = self._to_angles(x)\n",
        "        x = self.q(x).float()\n",
        "        x = self.from_q(x)\n",
        "\n",
        "        x = x.reshape(*prefix, self.dout)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm-q21_IWUCU",
        "outputId": "cfa85478-65d3-4074-fce1-dcd09285b7de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorcircuit\n",
            "  Downloading tensorcircuit-0.12.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorcircuit) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tensorcircuit) (1.16.0)\n",
            "Collecting tensornetwork-ng (from tensorcircuit)\n",
            "  Downloading tensornetwork_ng-0.5.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from tensorcircuit) (3.5)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from tensornetwork-ng->tensorcircuit) (0.21)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tensornetwork-ng->tensorcircuit) (3.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensornetwork-ng->tensorcircuit) (3.14.0)\n",
            "Downloading tensorcircuit-0.12.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.0/342.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensornetwork_ng-0.5.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.1/244.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensornetwork-ng, tensorcircuit\n",
            "Successfully installed tensorcircuit-0.12.0 tensornetwork-ng-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorcircuit.translation:Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
            "WARNING:tensorcircuit.translation:Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toy interaction matrix"
      ],
      "metadata": {
        "id": "X6d5fzsV4kt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    ParT interaction-feature encoder.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    n_heads per mhsa: output channels d′\n",
        "    hidden_channels : list[int] for intermediate 1×1 conv layers\n",
        "    eps             : numerical guard for log\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_heads: int = 8,\n",
        "                 hidden_channels: list[int] = (64, 64, 64),\n",
        "                 eps: float = 1e-8):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "        layers: list[nn.Module] = []\n",
        "        in_ch = 4                               # lnΔ, ln kT, ln z, ln m²\n",
        "        for h in hidden_channels:\n",
        "            layers += [\n",
        "                nn.Conv2d(in_ch, h, 1, bias=False),\n",
        "                nn.BatchNorm2d(h),\n",
        "                nn.GELU()\n",
        "            ]\n",
        "            in_ch = h\n",
        "        layers.append(nn.Conv2d(in_ch, n_heads, 1, bias=False))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x : (B, 4, N)  where the 4 dims are (E, px, py, pz)\n",
        "        returns\n",
        "        ------\n",
        "        U : (B, n_heads, N, N)  interaction embedding\n",
        "        \"\"\"\n",
        "        B, four, N = x.shape\n",
        "        assert four == 4, \"input must have 4 features: E, px, py, pz\"\n",
        "\n",
        "        # Split components\n",
        "        E, px, py, pz = x.unbind(dim=1)         # each (B, N)\n",
        "\n",
        "        # Basic kinematics ------------------------------------------------\n",
        "        pT = torch.sqrt(px**2 + py**2) + self.eps\n",
        "        phi = torch.atan2(py, px)               # (−π, π]\n",
        "        num = (E + pz).clamp(min=self.eps)  #need to avoid negative numbers\n",
        "        den = (E - pz).clamp(min=self.eps)\n",
        "        y   = 0.5 * torch.log(num / den)\n",
        "\n",
        "        # Expand to (B, N, N)\n",
        "        y_a, y_b = y.unsqueeze(2), y.unsqueeze(1)          # (B,N,1),(B,1,N)\n",
        "        phi_a, phi_b = phi.unsqueeze(2), phi.unsqueeze(1)\n",
        "        pT_a, pT_b = pT.unsqueeze(2), pT.unsqueeze(1)\n",
        "        E_a, E_b = E.unsqueeze(2), E.unsqueeze(1)\n",
        "        px_a, px_b = px.unsqueeze(2), px.unsqueeze(1)\n",
        "        py_a, py_b = py.unsqueeze(2), py.unsqueeze(1)\n",
        "        pz_a, pz_b = pz.unsqueeze(2), pz.unsqueeze(1)\n",
        "\n",
        "        # ΔR, kT, z\n",
        "        delta = torch.sqrt((y_a - y_b) ** 2 + (phi_a - phi_b) ** 2) + self.eps\n",
        "        kT = torch.minimum(pT_a, pT_b) * delta\n",
        "        z = torch.minimum(pT_a, pT_b) / (pT_a + pT_b + self.eps)\n",
        "\n",
        "        # m² of pair\n",
        "        E_sum = E_a + E_b\n",
        "        px_sum = px_a + px_b\n",
        "        py_sum = py_a + py_b\n",
        "        pz_sum = pz_a + pz_b\n",
        "        m2 = E_sum**2 - (px_sum**2 + py_sum**2 + pz_sum**2) + self.eps\n",
        "        m2 = torch.clamp(m2, min=self.eps)      # avoid negatives\n",
        "\n",
        "        # Stack → (B, 4, N, N)\n",
        "        feats = torch.stack([\n",
        "            torch.log(delta),\n",
        "            torch.log(kT),\n",
        "            torch.log(z),\n",
        "            torch.log(m2)\n",
        "        ], dim=1)\n",
        "\n",
        "        # conv\n",
        "        U = self.net(feats)                     # (B, n_heads, N, N)\n",
        "        return U\n",
        "\n",
        "\n",
        "\n",
        "B, _, N = x.shape\n",
        "n_heads = 2          # d′\n",
        "enc = InteractionEncoder(n_heads=n_heads)\n",
        "U = enc(x)\n",
        "print(\"U.shape:\", U.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOjDJYr14zDr",
        "outputId": "aa8b4aef-a5c1-4e3e-a125-6e86079468cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U.shape: torch.Size([1, 2, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particle Transformer"
      ],
      "metadata": {
        "id": "5CwQyoPYwaR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ParticleTokenizer(nn.Module):\n",
        "    def __init__(self, in_dim=4, out_dim=6):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (B, n_particles, in_dim)\n",
        "        returns: (B, n_particles, out_dim)\n",
        "        \"\"\"\n",
        "        x = x.transpose(1, 2)  # Input shape: (B, n_particles, in_dim) → (B, in_dim, n_particles)\n",
        "        return self.proj(x)\n",
        "\n",
        "tokenizer = ParticleTokenizer(4, 10)\n",
        "output = tokenizer(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya5SvxTJwE3r",
        "outputId": "27b1b1d0-4863-41b2-99f9-4daadd27688a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Same interface as your tiny MLP, but nn.Linear -> QuantumLinear.\n",
        "    Works for inputs shaped (..., dim).\n",
        "\n",
        "    Args:\n",
        "        dim         : feature size\n",
        "        dropout     : dropout prob\n",
        "        num_qubits  : qubits per QuantumLinear block (defaults to dim)\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, dropout=0., num_qubits=None):\n",
        "        super().__init__()\n",
        "        nq = num_qubits if num_qubits is not None else dim\n",
        "\n",
        "        self.fc1 = QuantumLinear(dim, dim, nq)\n",
        "        self.fc2 = QuantumLinear(dim, dim, nq)\n",
        "\n",
        "        self.act  = nn.GELU()\n",
        "        self.do1  = nn.Dropout(dropout)\n",
        "        self.do2  = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.do1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.do2(x)\n",
        "        return x\n",
        "\n",
        "# usage\n",
        "mlp = MLP(10, dropout=0.1)\n",
        "output = mlp(output)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5f8DTRY07PD",
        "outputId": "edb84881-2ccc-456a-bdc7-59ad23397fd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ParticleMHA(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head self-attention with quantum projections (q, k, v, o).\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    d            : embedding dim\n",
        "    heads        : number of attention heads\n",
        "    dropout      : dropout prob on attn weights\n",
        "    return_attn  : return attention maps?\n",
        "    num_qubits   : qubits per quantum block (defaults to d)\n",
        "    \"\"\"\n",
        "    def __init__(self, d: int, heads: int = 8,\n",
        "                 dropout: float = 0.1, return_attn: bool = False,\n",
        "                 num_qubits: int | None = None):\n",
        "        super().__init__()\n",
        "        assert d % heads == 0, \"`d` must be divisible by `heads`\"\n",
        "\n",
        "        self.d           = d\n",
        "        self.h           = heads\n",
        "        self.d_head      = d // heads\n",
        "        self.scale       = 1 / math.sqrt(self.d_head)\n",
        "        self.return_attn = return_attn\n",
        "\n",
        "        nq = num_qubits if num_qubits is not None else d\n",
        "\n",
        "        # quantum projections\n",
        "        self.q_proj = QuantumLinear(d, d, nq)\n",
        "        self.k_proj = QuantumLinear(d, d, nq)\n",
        "        self.v_proj = QuantumLinear(d, d, nq)\n",
        "        self.o_proj = QuantumLinear(d, d, nq)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def _split(self, t: torch.Tensor):\n",
        "        # (B, N, d) -> (B, H, N, d_head)\n",
        "        B, N, _ = t.shape\n",
        "        return t.view(B, N, self.h, self.d_head).transpose(1, 2)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, U: torch.Tensor | None = None):\n",
        "        B, N, _ = x.shape\n",
        "\n",
        "        Q = self._split(self.q_proj(x))\n",
        "        K = self._split(self.k_proj(x))\n",
        "        V = self._split(self.v_proj(x))\n",
        "\n",
        "        logits = (Q @ K.transpose(-2, -1)) * self.scale  # (B, H, N, N)\n",
        "\n",
        "        if U is not None:\n",
        "            logits = logits + U\n",
        "\n",
        "        attn = F.softmax(logits, dim=-1)\n",
        "        attn = self.drop(attn)\n",
        "\n",
        "        context = attn @ V  # (B, H, N, d_head)\n",
        "\n",
        "        context = (\n",
        "            context.transpose(1, 2)   # (B, N, H, d_head)\n",
        "                   .contiguous()\n",
        "                   .view(B, N, self.d)\n",
        "        )\n",
        "        out = self.o_proj(context)\n",
        "\n",
        "        if self.return_attn:\n",
        "            return out, attn\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "B, N, d = output.shape\n",
        "\n",
        "U = torch.randn(1, 2, N, N)  # broadcast to (B, H, N, N)\n",
        "\n",
        "pmha = ParticleMHA(d=d, heads=2, dropout=0.1, return_attn=True)\n",
        "output, A = pmha(output, U)          # out: (B, N, d)   A: (B, 8, N, N)\n",
        "\n",
        "print(output.shape, A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb5nYOsSyFRk",
        "outputId": "7335d6f6-9642-45ad-90b4-981175a47f6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 10]) torch.Size([1, 2, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transformer"
      ],
      "metadata": {
        "id": "4650yyFtdjaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MHA(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head attention (batch_first) with QuantumLinear projections.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    d_model : int          embedding dim\n",
        "    n_heads : int\n",
        "    dropout: float\n",
        "    bias   : bool          (ignored here, QuantumLinear has no bias)\n",
        "    num_qubits : int|None  qubits per quantum block (defaults to d_model)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, n_heads: int,\n",
        "                 dropout: float = 0., bias: bool = False,\n",
        "                 num_qubits: int | None = None):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"`d_model` must be divisible by `n_heads`\"\n",
        "        self.d_model = d_model\n",
        "        self.h       = n_heads\n",
        "        self.d_head  = d_model // n_heads\n",
        "        self.scale   = self.d_head ** -0.5\n",
        "\n",
        "        nq = num_qubits if num_qubits is not None else d_model\n",
        "\n",
        "        # Quantum projections replace nn.Linear\n",
        "        self.q_proj = QuantumLinear(d_model, d_model, nq)\n",
        "        self.k_proj = QuantumLinear(d_model, d_model, nq)\n",
        "        self.v_proj = QuantumLinear(d_model, d_model, nq)\n",
        "        self.o_proj = QuantumLinear(d_model, d_model, nq)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def _split_heads(self, x: torch.Tensor):\n",
        "        # (B, L, d_model) -> (B, h, L, d_head)\n",
        "        B, L, _ = x.shape\n",
        "        return x.view(B, L, self.h, self.d_head).transpose(1, 2)\n",
        "\n",
        "    def _merge_heads(self, x: torch.Tensor):\n",
        "        # (B, h, L, d_head) -> (B, L, d_model)\n",
        "        B, H, L, Dh = x.shape\n",
        "        return x.transpose(1, 2).contiguous().view(B, L, H * Dh)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        q: torch.Tensor,          # (B, Lq, d_model)\n",
        "        k: torch.Tensor,          # (B, Lk, d_model)\n",
        "        v: torch.Tensor,          # (B, Lk, d_model)\n",
        "        attn_mask: torch.Tensor | None = None,\n",
        "        key_padding_mask: torch.Tensor | None = None,\n",
        "        need_weights: bool = False\n",
        "    ):\n",
        "        B, Lq, _ = q.shape\n",
        "        _, Lk, _ = k.shape\n",
        "\n",
        "        Q = self._split_heads(self.q_proj(q))  # (B,h,Lq,d_h)\n",
        "        K = self._split_heads(self.k_proj(k))  # (B,h,Lk,d_h)\n",
        "        V = self._split_heads(self.v_proj(v))  # (B,h,Lk,d_h)\n",
        "\n",
        "        logits = torch.matmul(Q, K.transpose(-2, -1)) * self.scale  # (B,h,Lq,Lk)\n",
        "\n",
        "        attn = F.softmax(logits, dim=-1)\n",
        "        attn = self.drop(attn)\n",
        "\n",
        "        context = torch.matmul(attn, V)        # (B,h,Lq,d_h)\n",
        "\n",
        "        out = self.o_proj(self._merge_heads(context))  # (B,Lq,d_model)\n",
        "\n",
        "        if need_weights:\n",
        "            return out, attn.mean(dim=1)  # (B,Lq,Lk)\n",
        "        return out, None"
      ],
      "metadata": {
        "id": "CKYo7jEiyYx1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Particle attention block  (NormFormer style + U-bias)\n",
        "class ParticleAttentionBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, mlp_ratio=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.attn = ParticleMHA(dim, heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        self.mlp = MLP(dim, dropout)\n",
        "    def forward(self, x, U):\n",
        "        x = x + self.attn(self.ln1(x), U)    # bias-aware MHSA\n",
        "        x = x + self.mlp(self.ln2(x))        # feed-forward\n",
        "        return x\n",
        "\n",
        "# Class attention block  (CaiT style, no U)\n",
        "class ClassAttentionBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, mlp_ratio=4, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.attn = MHA(dim, heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        self.mlp = MLP(dim, dropout)\n",
        "    def forward(self, tokens, cls):          # tokens: (B,N,d), cls: (B,1,d)\n",
        "        z   = torch.cat([cls, tokens], dim=1)   # (B,1+N,d)\n",
        "        q   = self.ln1(cls)\n",
        "        kv  = self.ln1(z)\n",
        "        cls = cls + self.attn(q, kv, kv, need_weights=False)[0]\n",
        "        cls = cls + self.mlp(self.ln2(cls))\n",
        "        return cls                             # (B,1,d)\n",
        "\n",
        "# Complete Particle Transformer\n",
        "class ParT(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_dim=4,          # (E,px,py,pz)\n",
        "                 embed_dim=10,\n",
        "                 n_heads=2,\n",
        "                 depth=2,           # particle blocks\n",
        "                 class_depth=2,     # class-attention blocks\n",
        "                 mlp_ratio=4,\n",
        "                 num_classes=10,\n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer = ParticleTokenizer(in_dim, embed_dim)\n",
        "        self.U_encoder = InteractionEncoder(n_heads=n_heads)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ParticleAttentionBlock(embed_dim, n_heads, mlp_ratio, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        self.class_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.cls_blocks = nn.ModuleList([\n",
        "            ClassAttentionBlock(embed_dim, n_heads, mlp_ratio, 0.0)\n",
        "            for _ in range(class_depth)\n",
        "        ])\n",
        "\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "        # weight init\n",
        "        nn.init.trunc_normal_(self.class_token, std=0.02)\n",
        "        nn.init.trunc_normal_(self.head.weight,  std=0.02)\n",
        "        nn.init.zeros_(self.head.bias)\n",
        "\n",
        "    def forward(self, x):               # x: (B,4,N)\n",
        "        B, _, N = x.shape\n",
        "\n",
        "        tokens = self.tokenizer(x)                  # (B,N,d)\n",
        "        U      = self.U_encoder(x)                  # (B,H,N,N)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            tokens = blk(tokens, U)                # (B,N,d)\n",
        "\n",
        "        cls = self.class_token.expand(B, -1, -1)    # (B,1,d)\n",
        "        for blk in self.cls_blocks:\n",
        "            cls = blk(tokens, cls)                 # (B,1,d)\n",
        "\n",
        "        logits = self.head(cls.squeeze(1))          # (B,10)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "iQveEBhldizq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B, _, N = x_batch.shape          # (3,4,8)\n",
        "model = ParT(in_dim=4,\n",
        "             embed_dim=10,\n",
        "             n_heads=2,\n",
        "             depth=2,\n",
        "             class_depth=2,\n",
        "             num_classes=10)\n",
        "\n",
        "logits = model(x_batch)          # forward pass\n",
        "print(\"logits:\", logits.shape)   # torch.Size([3, 10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-g5CQ2hfh2x",
        "outputId": "5a6e20d4-2855-46ad-a949-a19f9af36776"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_batch                    # (3, 4, 8)\n",
        "y_train = torch.tensor([0, 1, 2])    # dummy class labels for testing\n",
        "\n",
        "model = ParT(in_dim=4,\n",
        "             embed_dim=10,\n",
        "             n_heads=2,\n",
        "             depth=2,\n",
        "             class_depth=2,\n",
        "             num_classes=10)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "n_epochs = 250\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    logits = model(x_train)          # (3, 10)\n",
        "    loss = criterion(logits, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print every 5 epochs\n",
        "    if (epoch+1) % 5 == 0 or epoch == 0:\n",
        "        preds = logits.argmax(1)\n",
        "        acc   = (preds == y_train).float().mean().item()\n",
        "        print(f\"epoch {epoch+1:3d}  loss {loss.item():.4f}  acc {acc:.3f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    probs = torch.softmax(model(x_train), dim=1)\n",
        "print(\"softmax-probs\\n\", probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOr6fyLvfjgv",
        "outputId": "bc187fcb-b348-47ce-d71c-e52e55889367"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch   1  loss 2.3297  acc 0.000\n",
            "epoch   5  loss 2.2604  acc 0.000\n",
            "epoch  10  loss 2.1752  acc 0.333\n",
            "epoch  15  loss 2.0782  acc 0.333\n",
            "epoch  20  loss 1.9541  acc 0.333\n",
            "epoch  25  loss 1.8064  acc 0.333\n",
            "epoch  30  loss 1.6569  acc 0.333\n",
            "epoch  35  loss 1.5183  acc 0.333\n",
            "epoch  40  loss 1.3999  acc 0.333\n",
            "epoch  45  loss 1.3081  acc 0.333\n",
            "epoch  50  loss 1.2424  acc 0.333\n",
            "epoch  55  loss 1.1977  acc 0.333\n",
            "epoch  60  loss 1.1684  acc 0.333\n",
            "epoch  65  loss 1.1496  acc 0.333\n",
            "epoch  70  loss 1.1375  acc 0.333\n",
            "epoch  75  loss 1.1293  acc 0.333\n",
            "epoch  80  loss 1.1235  acc 0.333\n",
            "epoch  85  loss 1.1192  acc 0.333\n",
            "epoch  90  loss 1.1162  acc 0.333\n",
            "epoch  95  loss 1.1138  acc 0.333\n",
            "epoch 100  loss 1.1119  acc 0.333\n",
            "epoch 105  loss 1.1105  acc 0.333\n",
            "epoch 110  loss 1.1093  acc 0.333\n",
            "epoch 115  loss 1.1083  acc 0.333\n",
            "epoch 120  loss 1.1075  acc 0.333\n",
            "epoch 125  loss 1.1067  acc 0.333\n",
            "epoch 130  loss 1.1061  acc 0.333\n",
            "epoch 135  loss 1.1056  acc 0.333\n",
            "epoch 140  loss 1.1051  acc 0.333\n",
            "epoch 145  loss 1.1046  acc 0.333\n",
            "epoch 150  loss 1.1043  acc 0.333\n",
            "epoch 155  loss 1.1039  acc 0.333\n",
            "epoch 160  loss 1.1036  acc 0.333\n",
            "epoch 165  loss 1.1033  acc 0.333\n",
            "epoch 170  loss 1.1030  acc 0.333\n",
            "epoch 175  loss 1.1028  acc 0.333\n",
            "epoch 180  loss 1.1026  acc 0.333\n",
            "epoch 185  loss 1.1024  acc 0.333\n",
            "epoch 190  loss 1.1022  acc 0.333\n",
            "epoch 195  loss 1.1020  acc 0.333\n",
            "epoch 200  loss 1.1018  acc 0.333\n",
            "epoch 205  loss 1.1017  acc 0.333\n",
            "epoch 210  loss 1.1015  acc 0.333\n",
            "epoch 215  loss 1.1014  acc 0.333\n",
            "epoch 220  loss 1.1013  acc 0.333\n",
            "epoch 225  loss 1.1012  acc 0.333\n",
            "epoch 230  loss 1.1011  acc 0.333\n",
            "epoch 235  loss 1.1010  acc 0.333\n",
            "epoch 240  loss 1.1009  acc 0.333\n",
            "epoch 245  loss 1.1008  acc 0.333\n",
            "epoch 250  loss 1.1007  acc 0.333\n",
            "softmax-probs\n",
            " tensor([[3.3254e-01, 3.3260e-01, 3.3277e-01, 2.6419e-04, 2.7729e-04, 2.5344e-04,\n",
            "         3.0712e-04, 3.1026e-04, 3.2025e-04, 3.5913e-04],\n",
            "        [3.3253e-01, 3.3260e-01, 3.3278e-01, 2.6400e-04, 2.7708e-04, 2.5325e-04,\n",
            "         3.0691e-04, 3.1005e-04, 3.2001e-04, 3.5888e-04],\n",
            "        [3.3253e-01, 3.3260e-01, 3.3278e-01, 2.6388e-04, 2.7696e-04, 2.5314e-04,\n",
            "         3.0678e-04, 3.0992e-04, 3.1987e-04, 3.5873e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load official Data"
      ],
      "metadata": {
        "id": "Z7bm2U4EYwY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jet-universe/particle_transformer.git\n",
        "!cd particle_transformer\n",
        "!cd /content/particle_transformer\n",
        "!touch env.sh\n",
        "!chmod +x env.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES5wefiuY5ca",
        "outputId": "99ac4161-bab8-4015-81d0-ae740123a0e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'particle_transformer'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 101 (delta 38), reused 27 (delta 27), pack-reused 49 (from 1)\u001b[K\n",
            "Receiving objects: 100% (101/101), 28.08 MiB | 14.94 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/particle_transformer/get_datasets.py JetClass -d ./datasets\n",
        "!source env.sh\n",
        "import os, glob, tarfile\n",
        "os.environ['DATADIR_JetClass'] = os.path.abspath('./datasets/JetClass')\n",
        "data_dir  = os.environ['DATADIR_JetClass']\n",
        "!pip install awkward uproot vector\n",
        "from particle_transformer.dataloader import read_file\n",
        "\n",
        "tar_path = \"/content/datasets/JetClass/JetClass_Pythia_val_5M.tar\"\n",
        "\n",
        "extract_dir = \"/content/datasets/JetClass/JetClass_Pythia_val_5M\"\n",
        "os.makedirs(extract_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "5IVg4AkAK1xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cdcc78-2bd5-4eab-c180-f748fbc65e19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://zenodo.org/record/6619768/files/JetClass_Pythia_val_5M.tar to ./datasets/JetClass/JetClass_Pythia_val_5M.tar\n",
            "./datasets/JetClass/JetClass_Pythia_val_5M.tar: 100% 7.07G/7.07G [10:19<00:00, 12.3MiB/s]\n",
            "Updated dataset path in env.sh to \"DATADIR_JetClass=./datasets/JetClass\".\n",
            "Collecting awkward\n",
            "  Downloading awkward-2.8.5-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting uproot\n",
            "  Downloading uproot-5.6.3-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting vector\n",
            "  Downloading vector-1.6.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting awkward-cpp==47 (from awkward)\n",
            "  Downloading awkward_cpp-47-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.11/dist-packages (from awkward) (2025.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from awkward) (8.7.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from awkward) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from awkward) (25.0)\n",
            "Requirement already satisfied: cramjam>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from uproot) (2.10.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from uproot) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.13.0->awkward) (3.23.0)\n",
            "Downloading awkward-2.8.5-py3-none-any.whl (886 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.8/886.8 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading awkward_cpp-47-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (638 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m638.8/638.8 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uproot-5.6.3-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.8/382.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vector-1.6.3-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vector, awkward-cpp, awkward, uproot\n",
            "Successfully installed awkward-2.8.5 awkward-cpp-47 uproot-5.6.3 vector-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not any(fname.endswith(\".root\") for fname in os.listdir(extract_dir)):\n",
        "    print(\"⏬ extracting test-set…\")\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(path=extract_dir)\n",
        "pattern = os.path.join(extract_dir, 'val_5M', \"*.root\")\n",
        "files   = sorted(glob.glob(pattern))\n",
        "print(f\"Found {len(files)} ROOT files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QtS-37tY8wa",
        "outputId": "09cebca9-fb6c-459e-b75b-685679784bf0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ extracting test-set…\n",
            "Found 50 ROOT files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "all_x_parts = []\n",
        "all_ys = []\n",
        "\n",
        "num_file = 1\n",
        "for file in files:\n",
        "    num_file += 1\n",
        "    if num_file % 5 == 0:\n",
        "        x_part, x_jets, y = read_file(\n",
        "            file,\n",
        "            max_num_particles=8,\n",
        "            particle_features=['part_pt', 'part_eta', 'part_phi', 'part_energy'],\n",
        "            jet_features=['jet_pt', 'jet_eta', 'jet_phi', 'jet_energy'],\n",
        "            labels=[\n",
        "                'label_QCD', 'label_Hbb', 'label_Hcc', 'label_Hgg', 'label_H4q',\n",
        "                'label_Hqql', 'label_Zqq', 'label_Wqq', 'label_Tbqq', 'label_Tbl',\n",
        "            ]\n",
        "        )\n",
        "        all_x_parts.append(torch.tensor(x_part, dtype=torch.float32)[:100,:,:])\n",
        "        all_ys.append(torch.tensor(y, dtype=torch.float32)[:100,:])\n",
        "\n",
        "x_all = torch.cat(all_x_parts, dim=0)\n",
        "y_all = torch.cat(all_ys, dim=0)\n",
        "print(x_all.shape, y_all.shape)\n",
        "\n",
        "class JetDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "dataset = JetDataset(x_all, y_all)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "-q3rmopucyqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d9b813-ea09-4a33-e54c-222b66ce5e7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 4, 8]) torch.Size([1000, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ParT(\n",
        "    in_dim=4,           # part_pt, eta, phi, energy\n",
        "    embed_dim=10,\n",
        "    n_heads=2,\n",
        "    depth=2,\n",
        "    class_depth=2,\n",
        "    num_classes=10\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "4bNN4pfUfldh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "cGmJ9BJbfzL5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_idx, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)  # shape [batch, 10]\n",
        "\n",
        "        loss = loss_fn(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJZR1RgvgqXZ",
        "outputId": "7b88db76-d9df-4dbf-a0af-ae13a4fbb81d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.3056\n",
            "Epoch 2/100, Loss: 2.3032\n",
            "Epoch 3/100, Loss: 2.3018\n",
            "Epoch 4/100, Loss: 2.2987\n",
            "Epoch 5/100, Loss: 2.2935\n",
            "Epoch 6/100, Loss: 2.2955\n",
            "Epoch 7/100, Loss: 2.2838\n",
            "Epoch 8/100, Loss: 2.2749\n",
            "Epoch 9/100, Loss: 2.2692\n",
            "Epoch 10/100, Loss: 2.2611\n",
            "Epoch 11/100, Loss: 2.2566\n",
            "Epoch 12/100, Loss: 2.2437\n",
            "Epoch 13/100, Loss: 2.2414\n",
            "Epoch 14/100, Loss: 2.2341\n",
            "Epoch 15/100, Loss: 2.2255\n",
            "Epoch 16/100, Loss: 2.2330\n",
            "Epoch 17/100, Loss: 2.2221\n",
            "Epoch 18/100, Loss: 2.2226\n",
            "Epoch 19/100, Loss: 2.2205\n",
            "Epoch 20/100, Loss: 2.2116\n",
            "Epoch 21/100, Loss: 2.2099\n",
            "Epoch 22/100, Loss: 2.2131\n",
            "Epoch 23/100, Loss: 2.2063\n",
            "Epoch 24/100, Loss: 2.2195\n",
            "Epoch 25/100, Loss: 2.2166\n",
            "Epoch 26/100, Loss: 2.2140\n",
            "Epoch 27/100, Loss: 2.2045\n",
            "Epoch 28/100, Loss: 2.2064\n",
            "Epoch 29/100, Loss: 2.2087\n",
            "Epoch 30/100, Loss: 2.2087\n",
            "Epoch 31/100, Loss: 2.2096\n",
            "Epoch 32/100, Loss: 2.2064\n",
            "Epoch 33/100, Loss: 2.2051\n",
            "Epoch 34/100, Loss: 2.2003\n",
            "Epoch 35/100, Loss: 2.2138\n",
            "Epoch 36/100, Loss: 2.2038\n",
            "Epoch 37/100, Loss: 2.1994\n",
            "Epoch 38/100, Loss: 2.1936\n",
            "Epoch 39/100, Loss: 2.2029\n",
            "Epoch 40/100, Loss: 2.2045\n",
            "Epoch 41/100, Loss: 2.2124\n",
            "Epoch 42/100, Loss: 2.1949\n",
            "Epoch 43/100, Loss: 2.1994\n",
            "Epoch 44/100, Loss: 2.1981\n",
            "Epoch 45/100, Loss: 2.2010\n",
            "Epoch 46/100, Loss: 2.2036\n",
            "Epoch 47/100, Loss: 2.1906\n",
            "Epoch 48/100, Loss: 2.1960\n",
            "Epoch 49/100, Loss: 2.1875\n",
            "Epoch 50/100, Loss: 2.1938\n",
            "Epoch 51/100, Loss: 2.1916\n",
            "Epoch 52/100, Loss: 2.1815\n",
            "Epoch 53/100, Loss: 2.1875\n",
            "Epoch 54/100, Loss: 2.1931\n",
            "Epoch 55/100, Loss: 2.1950\n",
            "Epoch 56/100, Loss: 2.1820\n",
            "Epoch 57/100, Loss: 2.1887\n",
            "Epoch 58/100, Loss: 2.1857\n",
            "Epoch 59/100, Loss: 2.1884\n",
            "Epoch 60/100, Loss: 2.1908\n",
            "Epoch 61/100, Loss: 2.1738\n",
            "Epoch 62/100, Loss: 2.1753\n",
            "Epoch 63/100, Loss: 2.1776\n",
            "Epoch 64/100, Loss: 2.1713\n",
            "Epoch 65/100, Loss: 2.1603\n",
            "Epoch 66/100, Loss: 2.1666\n",
            "Epoch 67/100, Loss: 2.1701\n",
            "Epoch 68/100, Loss: 2.1823\n",
            "Epoch 69/100, Loss: 2.1682\n",
            "Epoch 70/100, Loss: 2.1808\n",
            "Epoch 71/100, Loss: 2.1734\n",
            "Epoch 72/100, Loss: 2.1667\n",
            "Epoch 73/100, Loss: 2.1597\n",
            "Epoch 74/100, Loss: 2.1635\n",
            "Epoch 75/100, Loss: 2.1517\n",
            "Epoch 76/100, Loss: 2.1617\n",
            "Epoch 77/100, Loss: 2.1848\n",
            "Epoch 78/100, Loss: 2.1804\n",
            "Epoch 79/100, Loss: 2.1683\n",
            "Epoch 80/100, Loss: 2.1565\n",
            "Epoch 81/100, Loss: 2.1649\n",
            "Epoch 82/100, Loss: 2.1577\n",
            "Epoch 83/100, Loss: 2.1343\n",
            "Epoch 84/100, Loss: 2.1675\n",
            "Epoch 85/100, Loss: 2.1410\n",
            "Epoch 86/100, Loss: 2.1302\n",
            "Epoch 87/100, Loss: 2.1299\n",
            "Epoch 88/100, Loss: 2.1272\n",
            "Epoch 89/100, Loss: 2.1290\n",
            "Epoch 90/100, Loss: 2.1543\n",
            "Epoch 91/100, Loss: 2.1378\n",
            "Epoch 92/100, Loss: 2.1691\n",
            "Epoch 93/100, Loss: 2.1342\n",
            "Epoch 94/100, Loss: 2.1216\n",
            "Epoch 95/100, Loss: 2.1249\n",
            "Epoch 96/100, Loss: 2.1066\n",
            "Epoch 97/100, Loss: 2.1149\n",
            "Epoch 98/100, Loss: 2.1009\n",
            "Epoch 99/100, Loss: 2.1167\n",
            "Epoch 100/100, Loss: 2.0952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import sigmoid, softmax\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = model(x)\n",
        "        labels = torch.argmax(y, dim=1)          # convert one-hot to class id\n",
        "        preds = torch.argmax(outputs, dim=1)     # predicted class\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += y.size(0)\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on full dataset: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "ogHJm4wFhBMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffea42e-0f4b-4364-9dff-0978122331d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on full dataset: 0.2010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "all_outputs = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = model(x)\n",
        "        all_outputs.append(outputs.cpu())\n",
        "        all_targets.append(y.cpu())\n",
        "\n",
        "# Concatenate batches\n",
        "all_outputs = torch.cat(all_outputs, dim=0)\n",
        "all_targets = torch.cat(all_targets, dim=0)\n",
        "\n",
        "# Apply sigmoid (if using BCEWithLogitsLoss)\n",
        "probs = sigmoid(all_outputs).numpy()  # shape: (N, C)\n",
        "true = all_targets.numpy()            # shape: (N, C)\n",
        "\n",
        "# Compute AUC for each class and average\n",
        "try:\n",
        "    auc_macro = roc_auc_score(true, probs, average='macro', multi_class='ovr')\n",
        "    print(f\"Macro-Averaged AUC: {auc_macro:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(\"AUC could not be computed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ehi3CwmaDhL",
        "outputId": "dc360542-831d-4cc6-e063-982c60499e9a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-Averaged AUC: 0.6697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPgU9VB2ajLT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}