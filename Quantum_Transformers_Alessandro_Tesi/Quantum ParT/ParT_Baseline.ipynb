{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "smpEEHlypz0p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toy Data"
      ],
      "metadata": {
        "id": "PAgmRCdTvyg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([[ 8.7541382e+01,  7.4368027e+01,  6.8198807e+01,  5.5106983e+01,\n",
        "         3.8173203e+01,  2.3811323e+01,  1.8535612e+01,  1.8095873e+01],\n",
        "       [-5.1816605e-02,  4.1964740e-01,  4.4769207e-01, -6.5377988e-02,\n",
        "         6.1878175e-01,  6.2997532e-01, -8.1161506e-02, -7.9315454e-02],\n",
        "       [ 2.4468634e+00,  2.2728169e+00,  2.2340939e+00,  2.6091626e+00,\n",
        "         1.8117365e+00,  1.7758595e+00,  2.3642292e+00,  2.5458102e+00],\n",
        "       [ 8.7658936e+01,  8.1014442e+01,  7.5148209e+01,  5.5224800e+01,\n",
        "         4.5717682e+01,  2.8694658e+01,  1.8596695e+01,  1.8153358e+01]])\n",
        "\n",
        "x_batch = torch.Tensor([[[ 8.7541382e+01,  7.4368027e+01,  6.8198807e+01,  5.5106983e+01,\n",
        "          3.8173203e+01,  2.3811323e+01,  1.8535612e+01,  1.8095873e+01],\n",
        "        [-5.1816605e-02,  4.1964740e-01,  4.4769207e-01, -6.5377988e-02,\n",
        "          6.1878175e-01,  6.2997532e-01, -8.1161506e-02, -7.9315454e-02],\n",
        "        [ 2.4468634e+00,  2.2728169e+00,  2.2340939e+00,  2.6091626e+00,\n",
        "          1.8117365e+00,  1.7758595e+00,  2.3642292e+00,  2.5458102e+00],\n",
        "        [ 8.7658936e+01,  8.1014442e+01,  7.5148209e+01,  5.5224800e+01,\n",
        "          4.5717682e+01,  2.8694658e+01,  1.8596695e+01,  1.8153358e+01]],\n",
        "\n",
        "       [[ 8.2484528e+01,  5.2682617e+01,  5.1243843e+01,  3.6217686e+01,\n",
        "          2.8948278e+01,  2.6579512e+01,  2.1946012e+01,  2.1011120e+01],\n",
        "        [-4.3566185e-01, -8.7309110e-01, -4.4896263e-01, -6.0569459e-01,\n",
        "         -4.8134822e-01, -7.0045888e-01, -6.0671657e-01, -5.7662535e-01],\n",
        "        [-1.9739739e+00, -2.4504409e+00, -1.9982951e+00, -1.4225215e+00,\n",
        "         -1.9399333e+00, -2.3558097e+00, -1.4185165e+00, -1.4236869e+00],\n",
        "        [ 9.0437065e+01,  7.4070679e+01,  5.6495895e+01,  4.3069641e+01,\n",
        "          3.2367134e+01,  3.3371326e+01,  2.6115334e+01,  2.4602446e+01]],\n",
        "\n",
        "       [[ 8.6492935e+01,  7.0192978e+01,  5.8423912e+01,  5.6638733e+01,\n",
        "          4.9270725e+01,  4.1237038e+01,  3.6133625e+01,  3.5519596e+01],\n",
        "        [ 1.4010678e-01,  2.7912292e-01,  1.4376265e-01,  3.4672296e-01,\n",
        "          3.4966472e-01,  1.0524009e-01,  1.2958543e-01,  3.3264065e-01],\n",
        "        [ 1.9334941e+00,  1.6967584e+00,  1.9219695e+00,  1.6735281e+00,\n",
        "          1.6587850e+00,  1.8386338e+00,  1.9120301e+00,  1.6680365e+00],\n",
        "        [ 8.7343246e+01,  7.2945129e+01,  5.9030762e+01,  6.0084766e+01,\n",
        "          5.2313778e+01,  4.1465607e+01,  3.6440781e+01,  3.7506149e+01]]])"
      ],
      "metadata": {
        "id": "2jsmzKcFvx4L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.unsqueeze(0) # batch dimension\n",
        "x.shape, x_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po7Fb1v37EJT",
        "outputId": "5a9e6be0-869f-4811-c3b7-4d372bc69462"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 4, 8]), torch.Size([3, 4, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toy interaction matrix"
      ],
      "metadata": {
        "id": "X6d5fzsV4kt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    ParT interaction-feature encoder.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    n_heads per mhsa: output channels d′\n",
        "    hidden_channels : list[int] for intermediate 1×1 conv layers\n",
        "    eps             : numerical guard for log\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_heads: int = 8,\n",
        "                 hidden_channels: list[int] = (64, 64, 64),\n",
        "                 eps: float = 1e-8):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "        layers: list[nn.Module] = []\n",
        "        in_ch = 4                               # lnΔ, ln kT, ln z, ln m²\n",
        "        for h in hidden_channels:\n",
        "            layers += [\n",
        "                nn.Conv2d(in_ch, h, 1, bias=False),\n",
        "                nn.BatchNorm2d(h),\n",
        "                nn.GELU()\n",
        "            ]\n",
        "            in_ch = h\n",
        "        layers.append(nn.Conv2d(in_ch, n_heads, 1, bias=False))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x : (B, 4, N)  where the 4 dims are (E, px, py, pz)\n",
        "        returns\n",
        "        ------\n",
        "        U : (B, n_heads, N, N)  interaction embedding\n",
        "        \"\"\"\n",
        "        B, four, N = x.shape\n",
        "        assert four == 4, \"input must have 4 features: E, px, py, pz\"\n",
        "\n",
        "        # Split components\n",
        "        E, px, py, pz = x.unbind(dim=1)         # each (B, N)\n",
        "\n",
        "        # Basic kinematics ------------------------------------------------\n",
        "        pT = torch.sqrt(px**2 + py**2) + self.eps\n",
        "        phi = torch.atan2(py, px)               # (−π, π]\n",
        "        num = (E + pz).clamp(min=self.eps)  #need to avoid negative numbers\n",
        "        den = (E - pz).clamp(min=self.eps)\n",
        "        y   = 0.5 * torch.log(num / den)\n",
        "\n",
        "        # Expand to (B, N, N)\n",
        "        y_a, y_b = y.unsqueeze(2), y.unsqueeze(1)          # (B,N,1),(B,1,N)\n",
        "        phi_a, phi_b = phi.unsqueeze(2), phi.unsqueeze(1)\n",
        "        pT_a, pT_b = pT.unsqueeze(2), pT.unsqueeze(1)\n",
        "        E_a, E_b = E.unsqueeze(2), E.unsqueeze(1)\n",
        "        px_a, px_b = px.unsqueeze(2), px.unsqueeze(1)\n",
        "        py_a, py_b = py.unsqueeze(2), py.unsqueeze(1)\n",
        "        pz_a, pz_b = pz.unsqueeze(2), pz.unsqueeze(1)\n",
        "\n",
        "        # ΔR, kT, z\n",
        "        delta = torch.sqrt((y_a - y_b) ** 2 + (phi_a - phi_b) ** 2) + self.eps\n",
        "        kT = torch.minimum(pT_a, pT_b) * delta\n",
        "        z = torch.minimum(pT_a, pT_b) / (pT_a + pT_b + self.eps)\n",
        "\n",
        "        # m² of pair\n",
        "        E_sum = E_a + E_b\n",
        "        px_sum = px_a + px_b\n",
        "        py_sum = py_a + py_b\n",
        "        pz_sum = pz_a + pz_b\n",
        "        m2 = E_sum**2 - (px_sum**2 + py_sum**2 + pz_sum**2) + self.eps\n",
        "        m2 = torch.clamp(m2, min=self.eps)      # avoid negatives\n",
        "\n",
        "        # Stack → (B, 4, N, N)\n",
        "        feats = torch.stack([\n",
        "            torch.log(delta),\n",
        "            torch.log(kT),\n",
        "            torch.log(z),\n",
        "            torch.log(m2)\n",
        "        ], dim=1)\n",
        "\n",
        "        # conv\n",
        "        U = self.net(feats)                     # (B, n_heads, N, N)\n",
        "        return U\n",
        "\n",
        "\n",
        "\n",
        "B, _, N = x.shape\n",
        "n_heads = 2          # d′\n",
        "enc = InteractionEncoder(n_heads=n_heads)\n",
        "U = enc(x)\n",
        "print(\"U.shape:\", U.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOjDJYr14zDr",
        "outputId": "c062e171-de41-4c9f-c97a-5d639620b233"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U.shape: torch.Size([1, 2, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particle Transformer"
      ],
      "metadata": {
        "id": "5CwQyoPYwaR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ParticleTokenizer(nn.Module):\n",
        "    def __init__(self, in_dim=4, out_dim=6):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (B, n_particles, in_dim)\n",
        "        returns: (B, n_particles, out_dim)\n",
        "        \"\"\"\n",
        "        x = x.transpose(1, 2)  # Input shape: (B, n_particles, in_dim) → (B, in_dim, n_particles)\n",
        "        return self.proj(x)\n",
        "\n",
        "tokenizer = ParticleTokenizer(4, 10)\n",
        "output = tokenizer(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya5SvxTJwE3r",
        "outputId": "6e347893-293b-4d76-d7d7-926c5382a670"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, expansion=1, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden = dim * expansion\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden), nn.GELU(), nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, dim), nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "mlp = MLP(10, expansion=1, dropout=0.1)\n",
        "output = mlp(output)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5f8DTRY07PD",
        "outputId": "e553e047-ead1-43da-eee4-001c715f7258"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ParticleMHA(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head self-attention with additive interaction bias U.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    x        : (B, N, d)        token / particle embeddings\n",
        "    U        : (broadcast → B, H, N, N) or None\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    out      : (B, N, d)        attention output\n",
        "    attn_map : (B, H, N, N)     attention weights (returned if\n",
        "                                 return_attn=True)\n",
        "    \"\"\"\n",
        "    def __init__(self, d: int, heads: int = 8,\n",
        "                 dropout: float = 0.1, return_attn: bool = False):\n",
        "        super().__init__()\n",
        "        assert d % heads == 0, \"`d` must be divisible by `heads`\"\n",
        "\n",
        "        self.d          = d\n",
        "        self.h          = heads\n",
        "        self.d_head     = d // heads\n",
        "        self.scale      = 1 / math.sqrt(self.d_head)\n",
        "        self.return_attn = return_attn\n",
        "\n",
        "        # Projections\n",
        "        self.q = nn.Linear(d, d, bias=False)\n",
        "        self.k = nn.Linear(d, d, bias=False)\n",
        "        self.v = nn.Linear(d, d, bias=False)\n",
        "        self.o = nn.Linear(d, d, bias=False)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def _split(self, t: torch.Tensor):\n",
        "        # (B, N, d) -> (B, H, N, d_head)\n",
        "        B, N, _ = t.shape\n",
        "        return (\n",
        "            t.view(B, N, self.h, self.d_head)       # (B, N, H, d_head)\n",
        "             .transpose(1, 2)                       # (B, H, N, d_head)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor,\n",
        "                U: torch.Tensor | None = None):\n",
        "        B, N, _ = x.shape\n",
        "\n",
        "        Q = self._split(self.q(x))\n",
        "        K = self._split(self.k(x))\n",
        "        V = self._split(self.v(x))\n",
        "\n",
        "        logits = (Q @ K.transpose(-2, -1)) * self.scale  # (B, H, N, N)\n",
        "\n",
        "        if U is not None:\n",
        "            logits = logits + U\n",
        "\n",
        "        attn = F.softmax(logits, dim=-1)\n",
        "        attn = self.drop(attn)\n",
        "\n",
        "        context = attn @ V                               # (B, H, N, d_h)\n",
        "\n",
        "        context = (\n",
        "            context.transpose(1, 2)                      # (B, N, H, d_h)\n",
        "                   .contiguous()\n",
        "                   .view(B, N, self.d)                   # (B, N, d)\n",
        "        )\n",
        "        out = self.o(context)\n",
        "\n",
        "        if self.return_attn:\n",
        "            return out, attn        # (B, N, d), (B, H, N, N)\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "B, N, d = output.shape\n",
        "U = torch.randn(1, 2, N, N)  # broadcast to (B, H, N, N)\n",
        "\n",
        "pmha = ParticleMHA(d=d, heads=2, dropout=0.1, return_attn=True)\n",
        "output, A = pmha(output, U)          # out: (B, N, d)  A: (B, n_heads, N, N)\n",
        "\n",
        "print(output.shape, A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb5nYOsSyFRk",
        "outputId": "0b34f9c7-b47b-4000-856e-e14ecf6c120b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 10]) torch.Size([1, 2, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transformer"
      ],
      "metadata": {
        "id": "4650yyFtdjaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MHA(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head attention (batch_first) implemented explicitly.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    d_model : int          embedding dim\n",
        "    n_heads : int\n",
        "    dropout: float\n",
        "    bias   : bool          use bias in projections\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0., bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"`d_model` must be divisible by `n_heads`\"\n",
        "        self.d_model  = d_model\n",
        "        self.h        = n_heads\n",
        "        self.d_head   = d_model // n_heads\n",
        "        self.scale    = self.d_head ** -0.5\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, d_model, bias=bias)\n",
        "        self.k_proj = nn.Linear(d_model, d_model, bias=bias)\n",
        "        self.v_proj = nn.Linear(d_model, d_model, bias=bias)\n",
        "        self.o_proj = nn.Linear(d_model, d_model, bias=bias)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def _split_heads(self, x: torch.Tensor):\n",
        "        # (B, L, d_model) -> (B, h, L, d_head)\n",
        "        B, L, _ = x.shape\n",
        "        return x.view(B, L, self.h, self.d_head).transpose(1, 2)\n",
        "\n",
        "    def _merge_heads(self, x: torch.Tensor):\n",
        "        # (B, h, L, d_head) -> (B, L, d_model)\n",
        "        B, H, L, Dh = x.shape\n",
        "        return x.transpose(1, 2).contiguous().view(B, L, H * Dh)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        q: torch.Tensor,          # (B, Lq, d_model)\n",
        "        k: torch.Tensor,          # (B, Lk, d_model)\n",
        "        v: torch.Tensor,          # (B, Lk, d_model)\n",
        "        need_weights: bool = False\n",
        "    ):\n",
        "        B, Lq, _ = q.shape\n",
        "        _, Lk, _ = k.shape\n",
        "\n",
        "        Q = self._split_heads(self.q_proj(q))    # (B,h,Lq,d_h)\n",
        "        K = self._split_heads(self.k_proj(k))    # (B,h,Lk,d_h)\n",
        "        V = self._split_heads(self.v_proj(v))    # (B,h,Lk,d_h)\n",
        "\n",
        "        logits = torch.matmul(Q, K.transpose(-2, -1)) * self.scale   # (B,h,Lq,Lk)\n",
        "\n",
        "        attn = F.softmax(logits, dim=-1)\n",
        "        attn = self.drop(attn)\n",
        "\n",
        "        context = torch.matmul(attn, V)          # (B,h,Lq,d_h)\n",
        "\n",
        "        # merge heads + output proj\n",
        "        out = self.o_proj(self._merge_heads(context))  # (B,Lq,d_model)\n",
        "\n",
        "        if need_weights:\n",
        "            avg_weights = attn.mean(dim=1)            # (B,Lq,Lk)\n",
        "            return out, avg_weights\n",
        "        return out, None"
      ],
      "metadata": {
        "id": "uHgMbZTo1jkU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Particle attention block  (NormFormer style + U-bias)\n",
        "class ParticleAttentionBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, mlp_ratio=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.attn = ParticleMHA(dim, heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        self.mlp = MLP(dim, mlp_ratio, dropout)\n",
        "    def forward(self, x, U):\n",
        "        x = x + self.attn(self.ln1(x), U)    # bias-aware MHSA\n",
        "        x = x + self.mlp(self.ln2(x))        # feed-forward\n",
        "        return x\n",
        "\n",
        "# Class attention block  (CaiT style, no U)\n",
        "class ClassAttentionBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, mlp_ratio=4, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.attn = MHA(dim, heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        self.mlp = MLP(dim, mlp_ratio, dropout)\n",
        "    def forward(self, tokens, cls):          # tokens: (B,N,d), cls: (B,1,d)\n",
        "        z   = torch.cat([cls, tokens], dim=1)   # (B,1+N,d)\n",
        "        q   = self.ln1(cls)\n",
        "        kv  = self.ln1(z)\n",
        "        cls = cls + self.attn(q, kv, kv, need_weights=False)[0]\n",
        "        cls = cls + self.mlp(self.ln2(cls))\n",
        "        return cls                             # (B,1,d)\n",
        "\n",
        "# Complete Particle Transformer\n",
        "class ParT(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_dim=4,          # (E,px,py,pz)\n",
        "                 embed_dim=10,\n",
        "                 n_heads=2,\n",
        "                 depth=2,           # particle blocks\n",
        "                 class_depth=2,     # class-attention blocks\n",
        "                 mlp_ratio=4,\n",
        "                 num_classes=10,\n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer = ParticleTokenizer(in_dim, embed_dim)\n",
        "        self.U_encoder = InteractionEncoder(n_heads=n_heads)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ParticleAttentionBlock(embed_dim, n_heads, mlp_ratio, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        self.class_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.cls_blocks = nn.ModuleList([\n",
        "            ClassAttentionBlock(embed_dim, n_heads, mlp_ratio, 0.0)\n",
        "            for _ in range(class_depth)\n",
        "        ])\n",
        "\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "        nn.init.trunc_normal_(self.class_token, std=0.02)\n",
        "        nn.init.trunc_normal_(self.head.weight,  std=0.02)\n",
        "        nn.init.zeros_(self.head.bias)\n",
        "\n",
        "    def forward(self, x):               # x: (B,4,N)\n",
        "        B, _, N = x.shape\n",
        "\n",
        "        tokens = self.tokenizer(x)                  # (B,N,d)\n",
        "        U      = self.U_encoder(x)                  # (B,H,N,N)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            tokens = blk(tokens, U)                # (B,N,d)\n",
        "\n",
        "        cls = self.class_token.expand(B, -1, -1)    # (B,1,d)\n",
        "        for blk in self.cls_blocks:\n",
        "            cls = blk(tokens, cls)                 # (B,1,d)\n",
        "\n",
        "        logits = self.head(cls.squeeze(1))          # (B,10)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "iQveEBhldizq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B, _, N = x_batch.shape          # (3,4,8)\n",
        "model = ParT(in_dim=4,\n",
        "             embed_dim=10,\n",
        "             n_heads=2,\n",
        "             depth=2,\n",
        "             class_depth=2,\n",
        "             num_classes=10)\n",
        "\n",
        "logits = model(x_batch)          # forward pass\n",
        "print(\"logits:\", logits.shape)   # -> torch.Size([3, 10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-g5CQ2hfh2x",
        "outputId": "ef81a92c-0aa7-4a94-8c19-72ff3d20a178"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_batch                    # (3, 4, 8)\n",
        "y_train = torch.tensor([0, 1, 2])    # dummy class labels for testing\n",
        "\n",
        "model = ParT(in_dim=4,\n",
        "             embed_dim=10,\n",
        "             n_heads=2,\n",
        "             depth=2,\n",
        "             class_depth=2,\n",
        "             num_classes=10)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "n_epochs = 250\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    logits = model(x_train)          # (3, 10)\n",
        "    loss = criterion(logits, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print every 50 epochs\n",
        "    if (epoch+1) % 50 == 0 or epoch == 0:\n",
        "        preds = logits.argmax(1)\n",
        "        acc   = (preds == y_train).float().mean().item()\n",
        "        print(f\"epoch {epoch+1:3d}  loss {loss.item():.4f}  acc {acc:.3f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    probs = torch.softmax(model(x_train), dim=1)\n",
        "print(\"softmax-probs\\n\", probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOr6fyLvfjgv",
        "outputId": "093278c3-6069-4f62-d8b9-efbb3db8caac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch   1  loss 2.3060  acc 0.000\n",
            "epoch  50  loss 1.1657  acc 0.333\n",
            "epoch 100  loss 1.0977  acc 0.667\n",
            "epoch 150  loss 0.8846  acc 1.000\n",
            "epoch 200  loss 0.0219  acc 1.000\n",
            "epoch 250  loss 0.0040  acc 1.000\n",
            "softmax-probs\n",
            " tensor([[9.9536e-01, 2.0938e-04, 3.2167e-03, 1.9185e-04, 1.4622e-04, 1.9616e-04,\n",
            "         1.6393e-04, 1.4288e-04, 2.2374e-04, 1.5239e-04],\n",
            "        [1.3350e-04, 9.9691e-01, 2.1701e-03, 1.5398e-04, 1.0111e-04, 1.5174e-04,\n",
            "         7.6620e-05, 1.2269e-04, 7.1940e-05, 1.1269e-04],\n",
            "        [1.4062e-03, 1.9185e-03, 9.9667e-01, 1.0295e-06, 7.4998e-07, 8.4284e-07,\n",
            "         6.6928e-07, 5.7153e-07, 5.3092e-07, 3.6395e-07]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load official Data"
      ],
      "metadata": {
        "id": "Z7bm2U4EYwY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Clone repo\n",
        "!git clone https://github.com/jet-universe/particle_transformer.git\n",
        "!cd particle_transformer\n",
        "!cd /content/particle_transformer\n",
        "!touch env.sh\n",
        "!chmod +x env.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES5wefiuY5ca",
        "outputId": "29c76f98-c96e-4d03-f009-2cc7f87cf313"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'particle_transformer'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 101 (delta 38), reused 27 (delta 27), pack-reused 49 (from 1)\u001b[K\n",
            "Receiving objects: 100% (101/101), 28.08 MiB | 12.26 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/particle_transformer/get_datasets.py JetClass -d ./datasets\n",
        "!source env.sh\n",
        "import os, glob, tarfile\n",
        "os.environ['DATADIR_JetClass'] = os.path.abspath('./datasets/JetClass')\n",
        "data_dir  = os.environ['DATADIR_JetClass']\n",
        "!pip install awkward uproot vector\n",
        "from particle_transformer.dataloader import read_file\n",
        "\n",
        "#  Path to the one and only thing downloaded\n",
        "tar_path = \"/content/datasets/JetClass/JetClass_Pythia_val_5M.tar\"\n",
        "extract_dir = \"/content/datasets/JetClass/JetClass_Pythia_val_5M\"\n",
        "os.makedirs(extract_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "5IVg4AkAK1xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070415ca-05ae-4e98-b1c2-50116ff2e38c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://zenodo.org/record/6619768/files/JetClass_Pythia_val_5M.tar to ./datasets/JetClass/JetClass_Pythia_val_5M.tar\n",
            "./datasets/JetClass/JetClass_Pythia_val_5M.tar: 100% 7.07G/7.07G [06:36<00:00, 19.1MiB/s]\n",
            "Updated dataset path in env.sh to \"DATADIR_JetClass=./datasets/JetClass\".\n",
            "Collecting awkward\n",
            "  Downloading awkward-2.8.5-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting uproot\n",
            "  Downloading uproot-5.6.3-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting vector\n",
            "  Downloading vector-1.6.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting awkward-cpp==47 (from awkward)\n",
            "  Downloading awkward_cpp-47-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.11/dist-packages (from awkward) (2025.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from awkward) (8.7.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from awkward) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from awkward) (25.0)\n",
            "Requirement already satisfied: cramjam>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from uproot) (2.10.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from uproot) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.13.0->awkward) (3.23.0)\n",
            "Downloading awkward-2.8.5-py3-none-any.whl (886 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.8/886.8 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading awkward_cpp-47-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (638 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m638.8/638.8 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uproot-5.6.3-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.8/382.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vector-1.6.3-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vector, awkward-cpp, awkward, uproot\n",
            "Successfully installed awkward-2.8.5 awkward-cpp-47 uproot-5.6.3 vector-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not any(fname.endswith(\".root\") for fname in os.listdir(extract_dir)):\n",
        "    print(\"⏬ extracting test-set…\")\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(path=extract_dir)\n",
        "\n",
        "#  Point glob at the real ROOT files\n",
        "pattern = os.path.join(extract_dir, 'val_5M', \"*.root\")\n",
        "files   = sorted(glob.glob(pattern))\n",
        "print(f\"Found {len(files)} ROOT files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QtS-37tY8wa",
        "outputId": "19c7abc3-375b-415a-dd20-08464323b74d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ extracting test-set…\n",
            "Found 50 ROOT files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "all_x_parts = []\n",
        "all_ys = []\n",
        "\n",
        "num_file = 1\n",
        "for file in files:\n",
        "    num_file += 1\n",
        "    if num_file % 5 == 0:\n",
        "        x_part, x_jets, y = read_file(\n",
        "            file,\n",
        "            max_num_particles=8,\n",
        "            particle_features=['part_pt', 'part_eta', 'part_phi', 'part_energy'],\n",
        "            jet_features=['jet_pt', 'jet_eta', 'jet_phi', 'jet_energy'],\n",
        "            labels=[\n",
        "                'label_QCD', 'label_Hbb', 'label_Hcc', 'label_Hgg', 'label_H4q',\n",
        "                'label_Hqql', 'label_Zqq', 'label_Wqq', 'label_Tbqq', 'label_Tbl',\n",
        "            ]\n",
        "        )\n",
        "        all_x_parts.append(torch.tensor(x_part, dtype=torch.float32)[:100,:,:])\n",
        "        all_ys.append(torch.tensor(y, dtype=torch.float32)[:100,:])\n",
        "\n",
        "x_all = torch.cat(all_x_parts, dim=0)\n",
        "y_all = torch.cat(all_ys, dim=0)\n",
        "print(x_all.shape, y_all.shape)\n",
        "\n",
        "class JetDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "dataset = JetDataset(x_all, y_all)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "-q3rmopucyqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1091b217-02ad-4d0e-83b1-a73e231d8426"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 4, 8]) torch.Size([1000, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ParT(\n",
        "    in_dim=4,           # part_pt, eta, phi, energy\n",
        "    embed_dim=10,\n",
        "    n_heads=2,\n",
        "    depth=2,\n",
        "    class_depth=2,\n",
        "    num_classes=10\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "4bNN4pfUfldh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "cGmJ9BJbfzL5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_idx, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)  # shape [batch, 10]\n",
        "\n",
        "        loss = loss_fn(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJZR1RgvgqXZ",
        "outputId": "e9b7efdc-1cb0-4a3f-cb23-ca54004f0304"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.3047\n",
            "Epoch 2/100, Loss: 2.3033\n",
            "Epoch 3/100, Loss: 2.3028\n",
            "Epoch 4/100, Loss: 2.3024\n",
            "Epoch 5/100, Loss: 2.3011\n",
            "Epoch 6/100, Loss: 2.2968\n",
            "Epoch 7/100, Loss: 2.2857\n",
            "Epoch 8/100, Loss: 2.2636\n",
            "Epoch 9/100, Loss: 2.2503\n",
            "Epoch 10/100, Loss: 2.2394\n",
            "Epoch 11/100, Loss: 2.2311\n",
            "Epoch 12/100, Loss: 2.2308\n",
            "Epoch 13/100, Loss: 2.2296\n",
            "Epoch 14/100, Loss: 2.2269\n",
            "Epoch 15/100, Loss: 2.2260\n",
            "Epoch 16/100, Loss: 2.2261\n",
            "Epoch 17/100, Loss: 2.2195\n",
            "Epoch 18/100, Loss: 2.2221\n",
            "Epoch 19/100, Loss: 2.2174\n",
            "Epoch 20/100, Loss: 2.2180\n",
            "Epoch 21/100, Loss: 2.2088\n",
            "Epoch 22/100, Loss: 2.2136\n",
            "Epoch 23/100, Loss: 2.2127\n",
            "Epoch 24/100, Loss: 2.2058\n",
            "Epoch 25/100, Loss: 2.2002\n",
            "Epoch 26/100, Loss: 2.1939\n",
            "Epoch 27/100, Loss: 2.1861\n",
            "Epoch 28/100, Loss: 2.1853\n",
            "Epoch 29/100, Loss: 2.1678\n",
            "Epoch 30/100, Loss: 2.1570\n",
            "Epoch 31/100, Loss: 2.1857\n",
            "Epoch 32/100, Loss: 2.1693\n",
            "Epoch 33/100, Loss: 2.1595\n",
            "Epoch 34/100, Loss: 2.1459\n",
            "Epoch 35/100, Loss: 2.1359\n",
            "Epoch 36/100, Loss: 2.1423\n",
            "Epoch 37/100, Loss: 2.1434\n",
            "Epoch 38/100, Loss: 2.1444\n",
            "Epoch 39/100, Loss: 2.1384\n",
            "Epoch 40/100, Loss: 2.1368\n",
            "Epoch 41/100, Loss: 2.1260\n",
            "Epoch 42/100, Loss: 2.1322\n",
            "Epoch 43/100, Loss: 2.1340\n",
            "Epoch 44/100, Loss: 2.1186\n",
            "Epoch 45/100, Loss: 2.1181\n",
            "Epoch 46/100, Loss: 2.1201\n",
            "Epoch 47/100, Loss: 2.1211\n",
            "Epoch 48/100, Loss: 2.1304\n",
            "Epoch 49/100, Loss: 2.1275\n",
            "Epoch 50/100, Loss: 2.1129\n",
            "Epoch 51/100, Loss: 2.1206\n",
            "Epoch 52/100, Loss: 2.1085\n",
            "Epoch 53/100, Loss: 2.1188\n",
            "Epoch 54/100, Loss: 2.1111\n",
            "Epoch 55/100, Loss: 2.1189\n",
            "Epoch 56/100, Loss: 2.1186\n",
            "Epoch 57/100, Loss: 2.1015\n",
            "Epoch 58/100, Loss: 2.1065\n",
            "Epoch 59/100, Loss: 2.1056\n",
            "Epoch 60/100, Loss: 2.0990\n",
            "Epoch 61/100, Loss: 2.1043\n",
            "Epoch 62/100, Loss: 2.1118\n",
            "Epoch 63/100, Loss: 2.1060\n",
            "Epoch 64/100, Loss: 2.1024\n",
            "Epoch 65/100, Loss: 2.1093\n",
            "Epoch 66/100, Loss: 2.1084\n",
            "Epoch 67/100, Loss: 2.0977\n",
            "Epoch 68/100, Loss: 2.1020\n",
            "Epoch 69/100, Loss: 2.0936\n",
            "Epoch 70/100, Loss: 2.0856\n",
            "Epoch 71/100, Loss: 2.0964\n",
            "Epoch 72/100, Loss: 2.1131\n",
            "Epoch 73/100, Loss: 2.0991\n",
            "Epoch 74/100, Loss: 2.1072\n",
            "Epoch 75/100, Loss: 2.0974\n",
            "Epoch 76/100, Loss: 2.0862\n",
            "Epoch 77/100, Loss: 2.0810\n",
            "Epoch 78/100, Loss: 2.0973\n",
            "Epoch 79/100, Loss: 2.0945\n",
            "Epoch 80/100, Loss: 2.0898\n",
            "Epoch 81/100, Loss: 2.0858\n",
            "Epoch 82/100, Loss: 2.0721\n",
            "Epoch 83/100, Loss: 2.0817\n",
            "Epoch 84/100, Loss: 2.0805\n",
            "Epoch 85/100, Loss: 2.0800\n",
            "Epoch 86/100, Loss: 2.0816\n",
            "Epoch 87/100, Loss: 2.0824\n",
            "Epoch 88/100, Loss: 2.0869\n",
            "Epoch 89/100, Loss: 2.0843\n",
            "Epoch 90/100, Loss: 2.0825\n",
            "Epoch 91/100, Loss: 2.0839\n",
            "Epoch 92/100, Loss: 2.0743\n",
            "Epoch 93/100, Loss: 2.0742\n",
            "Epoch 94/100, Loss: 2.0663\n",
            "Epoch 95/100, Loss: 2.0720\n",
            "Epoch 96/100, Loss: 2.0858\n",
            "Epoch 97/100, Loss: 2.0731\n",
            "Epoch 98/100, Loss: 2.0816\n",
            "Epoch 99/100, Loss: 2.0783\n",
            "Epoch 100/100, Loss: 2.0721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import sigmoid, softmax\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = model(x)\n",
        "        labels = torch.argmax(y, dim=1)          # convert one-hot to class id\n",
        "        preds = torch.argmax(outputs, dim=1)     # predicted class\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += y.size(0)\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on full dataset: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "ogHJm4wFhBMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801b47a5-d2db-4e0f-c07e-5028d0dd048f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on full dataset: 0.2280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "all_outputs = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = model(x)\n",
        "        all_outputs.append(outputs.cpu())\n",
        "        all_targets.append(y.cpu())\n",
        "\n",
        "# Concatenate batches\n",
        "all_outputs = torch.cat(all_outputs, dim=0)\n",
        "all_targets = torch.cat(all_targets, dim=0)\n",
        "\n",
        "# Apply sigmoid (if using BCEWithLogitsLoss)\n",
        "probs = sigmoid(all_outputs).numpy()  # shape: (N, C)\n",
        "true = all_targets.numpy()            # shape: (N, C)\n",
        "\n",
        "# Compute AUC for each class and average\n",
        "try:\n",
        "    auc_macro = roc_auc_score(true, probs, average='macro', multi_class='ovr')\n",
        "    print(f\"Macro-Averaged AUC: {auc_macro:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(\"AUC could not be computed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ehi3CwmaDhL",
        "outputId": "657e3d47-e294-4f45-fc83-2cb5e6fad282"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-Averaged AUC: 0.6726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPgU9VB2ajLT"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}